{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THm_cdXlnMHE"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lbf_axGpltfW",
    "outputId": "a7bc63dc-bd4c-415a-93c0-2a1980d051f8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'/content/combined_csv_file.csv')\n",
    "pd.DataFrame(df)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZAgplRYUu2Z1",
    "outputId": "cda81d0c-9c01-43e2-8477-722856a6ccf4"
   },
   "outputs": [],
   "source": [
    "number_of_rows = df.shape[0]  \n",
    "print(number_of_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skIEsDAZEb56"
   },
   "source": [
    "# EDA\n",
    " let's explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_m-JquDLQnV",
    "outputId": "a6d30a27-5634-4a02-967d-7d8edd52d8ea"
   },
   "outputs": [],
   "source": [
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6FsbT3N1LW55",
    "outputId": "b0771da9-31f8-4060-c5e9-05a5adf5b282"
   },
   "outputs": [],
   "source": [
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQPW5TYyLdGK",
    "outputId": "06c1f7c7-52f6-4da5-8790-1091986b20d5"
   },
   "outputs": [],
   "source": [
    "print(df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQ2RXMhoEUvy"
   },
   "outputs": [],
   "source": [
    "df['text length'] = df['sentiment_reasoning'].astype(str).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-l768z6Oiih"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "v0G2BXI0OXxk",
    "outputId": "67070e55-ff8c-47d5-c1ee-ab1e08d1765d"
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df,col='sentiment')\n",
    "g.map(plt.hist,'text length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "Bg9c7yZPqOGB",
    "outputId": "ec09f4ba-8313-422d-b545-583735150a8a"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='sentiment',data=df,palette='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2gvKVA1_dB1"
   },
   "outputs": [],
   "source": [
    "mixed_value = 'mixed'  \n",
    "df = df[df['sentiment'] != mixed_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oPkNOcuZjhfE",
    "outputId": "4f1a1557-0202-47b7-f3cd-f278ac7930bf"
   },
   "outputs": [],
   "source": [
    "\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "CueJWwoeDZfE",
    "outputId": "cd387213-02f9-49a9-9103-17a2008c0682"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='sentiment',data=df,palette='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-2lZG9gW9qU",
    "outputId": "761fcb20-2fe7-4796-d1c8-a0d9e1aac65e"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Check if the text is a string before applying lower()\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()  # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ù„Ø­Ø±ÙˆÙ ØµØºÙŠØ±Ø©\n",
    "        text = re.sub(r'\\s+', ' ', text)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©\n",
    "        text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø·\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ² ØºÙŠØ± Ø§Ù„Ù…Ù‡Ù…Ø©\n",
    "    # If not a string (e.g., NaN), return an empty string or handle it as needed\n",
    "    else:\n",
    "        text = \"\"  # or any other appropriate handling for non-string values\n",
    "    return text\n",
    "\n",
    "df['cleaned_summary'] = df['sentiment_reasoning'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "qQ5Z1mB6EPhU",
    "outputId": "b48b95df-7214-4c3d-e3e3-ad9d2d1cb0b2"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "id": "xAsOYxnzi9-x",
    "outputId": "638fa2ab-01ae-4572-81e4-cfd7a963eccd"
   },
   "outputs": [],
   "source": [
    "# prompt: stacked bar for the text length based on sentiment label\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'df' is your DataFrame and it has 'sentiment' and 'text length' columns\n",
    "sentiment_counts = df.groupby('sentiment')['text length'].count().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sentiment_counts.plot(kind='bar', x='sentiment', y='text length')\n",
    "plt.title('Text Length Distribution by Sentiment')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of Texts')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "B7QN4JJKifg-",
    "outputId": "97099f94-6926-47f0-bd10-7394dab51cb1"
   },
   "outputs": [],
   "source": [
    "# @title text length\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "df['text length'].plot(kind='hist', bins=20, title='text length')\n",
    "plt.gca().spines[['top', 'right',]].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CcUEzXjxDkUJ",
    "outputId": "cde44b3e-f5dc-47da-cbb7-29f055ad8a3a"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ø®ØªØ¨Ø§Ø±\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['cleaned_summary'], df['sentiment'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨:\", len(train_texts))\n",
    "print(\"Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±:\", len(test_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TFeERTBPYCok",
    "outputId": "2b42e2d3-933e-4bdd-ff87-1c369203c588"
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DcfWEy-exHZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from datasets import Dataset as HFDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413,
     "referenced_widgets": [
      "5a0fb7114e96478b8823cff190ebb1d4",
      "35410314854c40c6a4c68d63a55900ac",
      "636a4774d6b8437ba20c635ef9182bae",
      "5e5d25e2ca62415db64966e3850804fd",
      "dacd5c28b3334d73ac580e31cd7f712b",
      "e9de73195a0f4338b480f15ddea0006b",
      "3adc415d04964bc1b58d719896ab1c0a",
      "bf3ff250db2f49aa81eaebc00c022eae",
      "2e1177bf9da84d70a7ef304e07807d01",
      "fb20f30202c24847b38a843b483aa273",
      "40b7db2700764f23b0116e7e145140f1",
      "5f3e2e967ba141338e855fbd225261d1",
      "fe5c0ed86f6649ecb3d7ff83c02c39cc",
      "6ce7b1594092402ebfc40f3bcd31f764",
      "378f014dae3b4ba18e98eb72717cfafd",
      "03bfc4ec5e4747a794ac5f6765f10a47",
      "8a61a965f8204bc58f6603c27518b0e1",
      "c4f79a10c30542ee9cf22206145fc54d",
      "aa79e2923d184dbea846962f54c19390",
      "e6a5ca2f115042c4beac158004a807d6",
      "7be0ca35f14b4207834f8b2a895ab20f",
      "3e79ab67d26847b197a948964d857465"
     ]
    },
    "id": "6HHxdj5GfDso",
    "outputId": "6e0a14d3-09f0-44ef-fa77-6721d36726cc"
   },
   "outputs": [],
   "source": [
    "# ğŸ”¹ 2. ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù†ØµÙˆØµ ÙˆØ¯Ù…Ø¬ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ù…Ø¹ Ø§Ù„Ù…Ù„Ø®Øµ\n",
    "df[\"text\"] = df['source_title'] + \" \" + df[\"cleaned_summary\"]\n",
    "\n",
    "# ğŸ”¹ 3. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… (Labels)\n",
    "label_map = {\"neutral\": 0, \"positive\": 1, \"negative\": 2}\n",
    "df[\"label\"] = df[\"sentiment\"].map(label_map)\n",
    "\n",
    "# ğŸ”¹ 4. ØªØ­Ù…ÙŠÙ„ Tokenizer Ø§Ù„Ø®Ø§Øµ Ø¨Ù€ FinBERT\n",
    "model_name = \"yiyanghkust/finbert-tone\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# ğŸ”¹ 5. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¥Ù„Ù‰ Tokens\n",
    "\n",
    "encodings = tokenizer(df[\"text\"].tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1OfB3y7GgsRY"
   },
   "outputs": [],
   "source": [
    "# ğŸ”¹ 6. Ø¥Ù†Ø´Ø§Ø¡ Dataset Ù…Ù† Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ø§Ù„Ø®Ø§ØµØ©\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}, torch.tensor(self.labels[idx])\n",
    "\n",
    "train_dataset = NewsDataset(encodings, df[\"label\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fOGzZmhSg2gb"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ğŸ”¹ 7. ØªØ¬Ù‡ÙŠØ² DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "224cfaa4cdb84ea082da1b144f884c6c",
      "072eabc859f44629ac21197b36dad9b7",
      "6fd0f5063e2b4451a8039c2119a040be",
      "ef0ea1fcf64a435cba5aff36e96de57a",
      "64ffabaebf594976940294fc49b33f80",
      "63897559887841ffa543ed03c3b9a4b2",
      "ea168da397ef4ddfb74d91807d0067f9",
      "ed330420b88b48498268e428aa40d386",
      "79159d1904f5465fbe261ab6be10148d",
      "3e2da1c49e144f0fa106d3b4dfde7384",
      "1689c39c86124e27861c53f5e837e1cc"
     ]
    },
    "id": "0vbBwYuchDNK",
    "outputId": "6a815b77-9847-4014-c673-6fe264f34580"
   },
   "outputs": [],
   "source": [
    "# ğŸ”¹ 8. ØªØ­Ù…ÙŠÙ„ FinBERT Model (Pretrained) Ù…Ø¹ 3 ØªØµÙ†ÙŠÙØ§Øª\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 830,
     "referenced_widgets": [
      "c84bfc3a06104785b8b738a1f6e5b8d1",
      "a99119227f57484d988a6349d88ad470",
      "e985febdd302498cbc930e85669f184a",
      "cde2cd57aa0f4b67a4563b0c768d51de",
      "e0815d315aec4051b6a33dea8e3e6935",
      "a9724bd01711420c9f1f5843e3ca4582",
      "612c84c5138644ae9a526339f9dc5188",
      "60619c3e2ccb48b59478c3401c74dc80",
      "a7b4e8e62b87401cb5e028076acce4f0",
      "3bed05f65deb47cfa00d7c39312bb596",
      "dcc7f95fb1684bba9457efb6b3b01c2e"
     ]
    },
    "id": "zbikRkURhG98",
    "outputId": "d0ad897c-e4bc-4725-9554-91e7d7815b04"
   },
   "outputs": [],
   "source": [
    "# ğŸ”¹ 9. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¬Ù‡Ø§Ø² (GPU Ø¥Ø°Ø§ Ù…ØªÙˆÙØ±)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vxqflT1Zdypy",
    "outputId": "2574a27a-25ac-4386-e9f8-167ca63fc32e"
   },
   "outputs": [],
   "source": [
    "# ğŸ”¹ 10. ØªØ­Ø¯ÙŠØ¯ Optimizer ÙˆØ§Ù„Ù€ Loss Function\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# ğŸ”¹ 11. ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ğŸš€\n",
    "epochs = 3  # Ø¹Ø¯Ø¯ Ø§Ù„Ø¯ÙˆØ±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ©\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in loop:\n",
    "        inputs, labels = batch\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_description(f\"Epoch {epoch+1}\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sXYwvPThfMQW",
    "outputId": "f7207102-5165-4371-bb83-ef4a4d8747b6"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ğŸ”¹ 12. Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨\n",
    "model.save_pretrained(\"finbert_finetuned\")\n",
    "tokenizer.save_pretrained(\"finbert_finetuned\")\n",
    "print(\"âœ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªÙ… Ø­ÙØ¸Ù‡ Ø¨Ù†Ø¬Ø§Ø­!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vem0N6IM-srC",
    "outputId": "29103fac-8d8a-4323-81ba-f1db5bb7fd96"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "\n",
    "# ğŸ”¹ 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨\n",
    "model_path = \"finbert_finetuned\"  # ØªØ£ÙƒØ¯ Ø£Ù†Ù‡ Ù†ÙØ³ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø°ÙŠ Ø­ÙØ¸Øª ÙÙŠÙ‡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# ğŸ”¹ 2. ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¬Ù‡Ø§Ø² (GPU Ø¥Ù† ÙˆØ¬Ø¯)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()  # ØªÙØ¹ÙŠÙ„ ÙˆØ¶Ø¹ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…\n",
    "\n",
    "# ğŸ”¹ 3. Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n",
    "new_headlines = [\n",
    "    \"Tesla shares rise after record-breaking quarterly earnings\",\n",
    "    \"Apple stock falls due to global supply chain issues\",\n",
    "    \"Microsoft announces major acquisition in AI sector\"\n",
    "]\n",
    "\n",
    "# ğŸ”¹ 4. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¥Ù„Ù‰ Tokens\n",
    "encodings = tokenizer(new_headlines, truncation=True, padding=True, max_length=512, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# ğŸ”¹ 5. ØªÙ…Ø±ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encodings)\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)  # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø¥Ù„Ù‰ Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª\n",
    "\n",
    "# ğŸ”¹ 6. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ ØªØµÙ†ÙŠÙØ§Øª Ù…ÙÙ‡ÙˆÙ…Ø©\n",
    "label_map = {0: \"Neutral\", 1: \"Positive\", 2: \"Negative\"}\n",
    "predicted_labels = [label_map[np.argmax(pred.cpu().numpy())] for pred in predictions]\n",
    "\n",
    "# ğŸ”¹ 7. Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
    "for headline, sentiment in zip(new_headlines, predicted_labels):\n",
    "    print(f\"ğŸ“° Ø§Ù„Ø®Ø¨Ø±: {headline}\\nğŸ“Š Ø§Ù„ØªØµÙ†ÙŠÙ: {sentiment}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
